{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM with random split for early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T07:10:37.220081Z",
     "start_time": "2021-04-09T07:10:37.207311Z"
    }
   },
   "source": [
    "In Latin America, one popular method uses an algorithm to verify income qualification. It’s called the Proxy Means Test (or PMT). With PMT, agencies use a model that considers a family’s observable household attributes like the material of their walls and ceiling, or the assets found in the home to classify them and predict their level of need.\n",
    "\n",
    "While this is an improvement, accuracy remains a problem as the region’s population grows and poverty declines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from Original Kernel (edited by EAS):\n",
    "\n",
    "* This kernel runs training on the heads of housholds only\n",
    "* It seems to be very important to balance class frequencies.\n",
    "* This kernel uses macro F1 score to early stopping in training.\n",
    "* Categoricals are turned into numbers with proper mapping instead of blind label encoding.\n",
    "* OHE if reversed into label encoding, as it is easier to digest for a tree model.\n",
    "* idhogar is NOT used in training. \n",
    "* There are aggregations done within households and new features are hand-crafted.\n",
    "* A voting classifier is used to average over several LightGBM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:24.954257Z",
     "start_time": "2021-04-16T07:17:23.007672Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KMSUNG\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode_data(), feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:24.970256Z",
     "start_time": "2021-04-16T07:17:24.956258Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# this only transforms the idhogar field, the other things this function used to do are done elsewhere\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "# plot feature importance for sklearn decision trees    \n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    if display_results:\n",
    "        # Print the feature ranking\n",
    "        print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" - \" + X_train.columns[indices[f]])\n",
    "        \n",
    "        ranked_list.append(X_train.columns[indices[f]])\n",
    "        \n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(X_train.columns[indices[f]])\n",
    "            \n",
    "    return ranked_list, zero_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoder\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:24.986307Z",
     "start_time": "2021-04-16T07:17:24.975334Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n",
    "                 ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                 ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                 ('human_density', 'tamviv', 'rooms'),\n",
    "                 ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                 ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                 ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                 ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                 ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "                ]\n",
    "    \n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "    \n",
    "    # tamviv, number of persons living in the household\n",
    "\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "    \n",
    "    # aggregation rules over household\n",
    "    aggs_num = {'age': ['min', 'max', 'mean'],\n",
    "                'escolari': ['min', 'max', 'mean']\n",
    "               }\n",
    "    \n",
    "    aggs_cat = {'dis': ['mean']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "\n",
    "    # aggregation over household\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]: # 조건 부합 데이터 추출\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "\n",
    "    # Drop id's\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agg 함수\n",
    "\n",
    "- 모든열에 여러 함수를 매핑 : group객체.agg([함수1,함수2,함수3,…])\n",
    "- 각 열마다 다른 함수를 매핑 : group객체.agg({‘열1’: 함수1, ‘열2’:함수2, …})\n",
    "\n",
    "** : https://www.daleseo.com/python-ditonary/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_OHE2LE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.001672Z",
     "start_time": "2021-04-16T07:17:24.988185Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert one hot encoded fields to label encoding\n",
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n",
    "               'instlevel', 'lugar', 'tipovivi',\n",
    "               'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        #deal with those OHE, where there is a sum over columns == 0\n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n",
    "                  .format(s_))\n",
    "            # dummy colmn name to be added\n",
    "            col_dummy = s_+'_dummy'\n",
    "            # add the column to the dataframe\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            # add the name to the list of columns to be label-encoded\n",
    "            cols_s_.append(col_dummy)\n",
    "            # proof-check, that now the category is complete\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                 print(\"The category completion did not work\")\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the data and clean it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.257298Z",
     "start_time": "2021-04-16T07:17:25.003671Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/temp/train.csv')\n",
    "test = pd.read_csv('C:/temp/test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.592963Z",
     "start_time": "2021-04-16T07:17:25.260323Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    encode_data(df_)\n",
    "    \n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up some missing data and convert objects to numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dependency 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.608357Z",
     "start_time": "2021-04-16T07:17:25.594903Z"
    }
   },
   "outputs": [],
   "source": [
    "train['dependency'] = np.sqrt(train['SQBdependency'])  # SQBdependency, dependency squared\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### years of education 변수 \"no\" -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.639895Z",
     "start_time": "2021-04-16T07:17:25.610400Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0 meaneduc,average years of education for adults (18+)\n",
    " \n",
    " 여성 가장의 교육년수, yes=1 and no=0 \n",
    " \n",
    " \n",
    "  - edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "  \n",
    "  남성 가장의 교육년수, yes=1 and no=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### escolari 변수로 household & education 으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.671923Z",
     "start_time": "2021-04-16T07:17:25.641808Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1)\n",
    "          , \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\")&(train['parentesco1'] == 1)\n",
    "                                  , \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1)\n",
    "          , \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\")&(train['parentesco1'] == 1)\n",
    "                                  , \"escolari\"]\n",
    "\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1)\n",
    "         , \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\")&(test['parentesco1']==1)\n",
    "                                , \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1)\n",
    "         , \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\")&(test['parentesco1'] == 1)\n",
    "                                , \"escolari\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - escolari, years of schooling\n",
    " - parentesco1, =1 if household head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### years of education가 \"yes\" 인 경우는 정확히 몇년인지 모름 -> 4로 채움\n",
    "\n",
    "왜 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.686926Z",
     "start_time": "2021-04-16T07:17:25.673926Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.702925Z",
     "start_time": "2021-04-16T07:17:25.687930Z"
    }
   },
   "outputs": [],
   "source": [
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수생성 (가장인 사람의 max years of education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.717958Z",
     "start_time": "2021-04-16T07:17:25.704925Z"
    }
   },
   "outputs": [],
   "source": [
    "train['edjef'] = np.max(train[['edjefa', 'edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa', 'edjefe']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.733928Z",
     "start_time": "2021-04-16T07:17:25.719926Z"
    }
   },
   "outputs": [],
   "source": [
    "train['v2a1'].isnull().sum()\n",
    "train['v2a1']=train['v2a1'].fillna(0)\n",
    "test['v2a1']=test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1']=test['v18q1'].fillna(0)\n",
    "train['v18q1']=train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc']=train['rez_esc'].fillna(0)\n",
    "test['rez_esc']=test['rez_esc'].fillna(0)\n",
    "\n",
    "train['meaneduc'].isnull().sum()\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모순되는 부분 고치기 - 물이 없다고 하면 화장실 없다고 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.749926Z",
     "start_time": "2021-04-16T07:17:25.734927Z"
    }
   },
   "outputs": [],
   "source": [
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - dependency, Dependency rate, calculated = (number of members of the household younger than 19 or older than 64)/(number of member of household between 19 and 64)\n",
    " \n",
    " 의존성 비율, (19세 미만 또는 64세 이상 가구원 수)/(19~64세 가구원 수)\n",
    " \n",
    " \n",
    " - edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0 meaneduc,average years of education for adults (18+)\n",
    " \n",
    " 여성 가장의 교육년수, yes=1 and no=0 \n",
    " \n",
    " \n",
    "  - edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "  \n",
    "  남성 가장의 교육년수, yes=1 and no=0\n",
    "  \n",
    "  \n",
    "  - escolari, years of schooling\n",
    "  - parentesco1, =1 if household head\n",
    "  - v14a, =1 has toilet in the household\n",
    "  - sanitario1, =1 no toilet in the dwelling\n",
    "  - abastaguano, =1 if no water provision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T07:46:56.241078Z",
     "start_time": "2021-04-09T07:46:56.235439Z"
    }
   },
   "source": [
    "## train_test_apply_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:25.765926Z",
     "start_time": "2021-04-16T07:17:25.750927Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "    \n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_ = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "    \n",
    "    del xx, xx_func\n",
    "    return train_, test_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_OHE2LE 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:26.799729Z",
     "start_time": "2021-04-16T07:17:25.766926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "# 라벨인코딩\n",
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:26.815649Z",
     "start_time": "2021-04-16T07:17:26.801649Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age\n",
    "- meanduc, average years of education for adults (18+)\n",
    "- hogar_nin, Number of children 0 to 19 in household\n",
    "- hogar_adul, Number of adults in household\n",
    "- hogar_mayor, Number of individuals 65+ in the household\n",
    "- hogar_total, Number of total individuals in the household\n",
    "- bedrooms, Number of bedrooms\n",
    "- overcrowding, Number persons per room"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert_geo2aggs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:26.959313Z",
     "start_time": "2021-04-16T07:17:26.818655Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)]\n",
    "                        , pd.get_dummies(df_[cols_2_ohe], columns = cols_2_ohe)]\n",
    "                       ,axis=1)\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE', 'idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_dummies 함수\n",
    "\n",
    "https://zephyrus1111.tistory.com/91\n",
    "\n",
    "- idhogar, this is a unique identifier for each household. This can be used to create household-wide features, etc. All rows in a given household will have a matching value for this identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T07:52:49.914211Z",
     "start_time": "2021-04-09T07:52:49.909737Z"
    }
   },
   "source": [
    "## 'num_over_18'\n",
    "\n",
    "가정 별 18세 이상의 구성원 수 (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.038792Z",
     "start_time": "2021-04-16T07:17:26.960308Z"
    }
   },
   "outputs": [],
   "source": [
    "train['num_over_18'] = 0\n",
    "train['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "train['num_over_18'] = train['num_over_18'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.054060Z",
     "start_time": "2021-04-16T07:17:27.039794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       2.0\n",
       "4       2.0\n",
       "       ... \n",
       "9552    4.0\n",
       "9553    4.0\n",
       "9554    4.0\n",
       "9555    4.0\n",
       "9556    4.0\n",
       "Name: num_over_18, Length: 9557, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2번째 실행 후\n",
    "train['num_over_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.070128Z",
     "start_time": "2021-04-16T07:17:27.058108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       2.0\n",
       "4       2.0\n",
       "       ... \n",
       "9552    4.0\n",
       "9553    4.0\n",
       "9554    4.0\n",
       "9555    4.0\n",
       "9556    4.0\n",
       "Name: num_over_18, Length: 9557, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3번째 실행 후\n",
    "train['num_over_18']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.195544Z",
     "start_time": "2021-04-16T07:17:27.074061Z"
    }
   },
   "outputs": [],
   "source": [
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "test['num_over_18'] = test['num_over_18'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add some extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.227599Z",
     "start_time": "2021-04-16T07:17:27.196547Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    # tamhog - size of the household\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] \n",
    "    # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] \n",
    "    # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] \n",
    "    # rent to people in household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/df['r4t3'] \n",
    "    # rent to people under age 12\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1']) \n",
    "    # rooms per person\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms'] \n",
    "    # rent to household size\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize'] \n",
    "    # some households have no one over 18, use the total rent for those\n",
    "    df['rent_to_over_18'] = df['v2a1']/df['num_over_18']\n",
    "    \n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n",
    "    \n",
    "extract_features(train)    \n",
    "extract_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- v2a1, Monthly rent payment\n",
    "- tamhog, size of the household\n",
    "- r4t3, Total persons in the household\n",
    "- r4t1, persons younger than 12 years of age\n",
    "- hhsize, household size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.258726Z",
     "start_time": "2021-04-16T07:17:27.229603Z"
    }
   },
   "outputs": [],
   "source": [
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]  # 도대체 무슨소리\n",
    "\n",
    "needless_cols.extend(instlevel_cols) # 리스트에 추가\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data\n",
    "\n",
    "We split the data by household to avoid leakage, since rows belonging to the same household usually have the same target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.274751Z",
     "start_time": "2021-04-16T07:17:27.259665Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.2, seed=None):\n",
    "    train2 = train.copy()\n",
    "    \n",
    "    cv_hhs = np.random.choice(households, size=int(len(households)*test_percentage), replace=False)\n",
    "    \n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "    \n",
    "    X_train = train2[~cv_idx] \n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]  # sample_weight 의 역할은?\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.isin()\n",
    "\n",
    "내가 찾는게 있는지 여부를 각 index 위치에 True, False 형태로  알려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.305771Z",
     "start_time": "2021-04-16T07:17:27.275750Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.query('parentesco1==1')\n",
    "\n",
    "# pull out and drop the target variable\n",
    "y = X['Target'] - 1\n",
    "X = X.drop(['Target'], axis=1)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "\n",
    "train2 = X.copy()\n",
    "\n",
    "train_hhs = train2.idhogar\n",
    "\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n",
    "\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "# train on entire dataset\n",
    "X_train = train2\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.320938Z",
     "start_time": "2021-04-16T07:17:27.306777Z"
    }
   },
   "outputs": [],
   "source": [
    "# figure out the class weights for training with unbalanced classes\n",
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute sample weight\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_sample_weight.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.335911Z",
     "start_time": "2021-04-16T07:17:27.321897Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop some features which aren't used by the LGBM or have very low importance\n",
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN',\n",
    " 'agg18_estadocivil6_COUNT',\n",
    " 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT',\n",
    " 'agg18_parentesco11_COUNT',\n",
    " 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT',\n",
    " 'agg18_parentesco2_COUNT',\n",
    " 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT',\n",
    " 'agg18_parentesco5_COUNT',\n",
    " 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT',\n",
    " 'agg18_parentesco8_COUNT',\n",
    " 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4',\n",
    " 'geo_energcocinar_LE_1',\n",
    " 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0',\n",
    " 'geo_hogar_mayor',\n",
    " 'geo_manual_elec_LE_2',\n",
    " 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4',\n",
    " 'geo_pared_LE_5',\n",
    " 'geo_pared_LE_6',\n",
    " 'num_over_18',\n",
    " 'parentesco_LE',\n",
    " 'rez_esc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.351071Z",
     "start_time": "2021-04-16T07:17:27.336924Z"
    }
   },
   "outputs": [],
   "source": [
    "xgb_drop_cols = extra_drop_features + [\"idhogar\",  'parentesco1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a voting classifier\n",
    "\n",
    "Vote based on LGBM models with early stopping based on macro F1 and decaying learning rate.\n",
    "\n",
    "RandomizedSearchCV로 하이퍼파라미터 튜닝\n",
    "(https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "\n",
    "(https://www.kaggle.com/mlisovyi/lighgbm-hyperoptimisation-with-f1-macro)\n",
    "\n",
    "Grid Search is good when we work with a small number of hyperparameters. However, if the number of parameters to consider is particularly high and the magnitudes of influence are imbalanced, the better choice is to use the Random Search.\n",
    "\n",
    "https://towardsdatascience.com/machine-learning-gridsearchcv-randomizedsearchcv-d36b89231b10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.367129Z",
     "start_time": "2021-04-16T07:17:27.352085Z"
    }
   },
   "outputs": [],
   "source": [
    "# 4\n",
    "opt_parameters = {'max_depth':35, 'eta':0.1, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 1, 'num_class': 4, 'gamma': 2.0, 'colsample_bylevel': 0.9, 'subsample': 0.84, 'colsample_bytree': 0.88, 'reg_lambda': 0.40 }\n",
    "# 5\n",
    "opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.5, 'colsample_bylevel': 1, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "# 6\n",
    "# opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.75, 'colsample_bylevel': 0.95, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "# # 7\n",
    "# opt_parameters = {'max_depth':35, 'eta':0.12, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 3.25, 'colsample_bylevel': 0.95, 'subsample': 0.88, 'colsample_bytree': 0.88, 'reg_lambda': 0.35 }\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1) \n",
    "\n",
    "fit_params={\"early_stopping_rounds\":500,\n",
    "            \"eval_metric\" : evaluate_macroF1_lgb, \n",
    "            \"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n",
    "            'verbose': False,\n",
    "           }\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* argmax(axis=0) : 각 열을 따라 가장 높은 값의 인덱스를 제공\n",
    "(https://www.delftstack.com/ko/api/numpy/python-numpy-argmax/)\n",
    "\n",
    "* f1_score(y_true, y_pred, average='macro') : truth : 실제값, pred_labels : 예측값\n",
    "//average를 macro로 두면 각 열에 대한 precision 값을 모두 더한 다음 열의 갯수로 나눈 것입니다.\n",
    "\n",
    "* np.power(a, b) : a^b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:17:27.397039Z",
     "start_time": "2021-04-16T07:17:27.368117Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "    \n",
    "    # randomly split the data so we have a test set for early stopping\n",
    "    if sample_weight is not None:\n",
    "        X_train, y_train, X_test, y_test, y_train_weight = split_data(X, y, sample_weight, households=train_households)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = split_data(X, y, None, households=train_households)\n",
    "        \n",
    "    # update the fit params with our new split\n",
    "    fit_params[\"eval_set\"] = [(X_test,y_test)]\n",
    "    \n",
    "    # fit the estimator\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train) # 자료형 확인\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, **fit_params)\n",
    "    \n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) \n",
    "            and not isinstance(estimator1, RandomForestClassifier) \n",
    "            and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss']) # mlogloss : Multiclass logloss (손실함수)\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "        # evals_result : 결괏값 리턴\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n",
    "        best_cv = f1_score(y_test, estimator.predict(X_test), average=\"macro\")\n",
    "        print(\"Train F1:\", best_train)\n",
    "        print(\"Test F1:\", best_cv)\n",
    "        \n",
    "    # reject some estimators based on their performance on train and test sets\n",
    "    if threshold:\n",
    "        # if the valid score is very high we'll allow a little more leeway with the train scores\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "\n",
    "        # else recurse until we get a better one\n",
    "        else:\n",
    "            print(\"Unacceptable!!! Trying again...\")\n",
    "            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n",
    "    \n",
    "    else:\n",
    "        return estimator\n",
    "    \n",
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    '''\n",
    "    This implements the fit method of the VotingClassifier propagating fit_params\n",
    "    '''\n",
    "    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        \n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output'\n",
    "                                      ' classification is not supported.')\n",
    "\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
    "                             % self.voting)\n",
    "\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n",
    "                                 ' should be a list of (string, estimator)'\n",
    "                                 ' tuples')\n",
    "\n",
    "        if (self.weights is not None and\n",
    "                len(self.weights) != len(self.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d estimators'\n",
    "                             % (len(self.weights), len(self.estimators)))\n",
    "\n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is '\n",
    "                             'required to be a classifier!')\n",
    "\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
    "                delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n",
    "                                                 sample_weight=sample_weight, threshold=threshold, **fit_params)\n",
    "                for clf in clfs if clf is not None)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:23:16.151589Z",
     "start_time": "2021-04-16T07:17:27.397978Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29894\tvalidation_0-macroF1:0.63874\n",
      "[50]\tvalidation_0-mlogloss:0.89615\tvalidation_0-macroF1:0.56756\n",
      "[100]\tvalidation_0-mlogloss:0.89371\tvalidation_0-macroF1:0.55565\n",
      "[150]\tvalidation_0-mlogloss:0.89062\tvalidation_0-macroF1:0.56537\n",
      "[200]\tvalidation_0-mlogloss:0.89161\tvalidation_0-macroF1:0.56447\n",
      "[250]\tvalidation_0-mlogloss:0.89255\tvalidation_0-macroF1:0.56603\n",
      "[299]\tvalidation_0-mlogloss:0.89179\tvalidation_0-macroF1:0.56650\n",
      "Train F1: 0.9115660908746297\n",
      "Test F1: 0.44462641001160175\n",
      "[16:17:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:17:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30399\tvalidation_0-macroF1:0.62540\n",
      "[50]\tvalidation_0-mlogloss:0.91589\tvalidation_0-macroF1:0.58098\n",
      "[100]\tvalidation_0-mlogloss:0.91543\tvalidation_0-macroF1:0.59476\n",
      "[150]\tvalidation_0-mlogloss:0.91787\tvalidation_0-macroF1:0.60346\n",
      "[200]\tvalidation_0-mlogloss:0.91642\tvalidation_0-macroF1:0.60225\n",
      "[250]\tvalidation_0-mlogloss:0.91610\tvalidation_0-macroF1:0.60209\n",
      "[299]\tvalidation_0-mlogloss:0.91594\tvalidation_0-macroF1:0.60731\n",
      "Train F1: 0.8976233528333496\n",
      "Test F1: 0.4299722420279911\n",
      "[16:18:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30003\tvalidation_0-macroF1:0.60316\n",
      "[50]\tvalidation_0-mlogloss:0.94443\tvalidation_0-macroF1:0.59214\n",
      "[100]\tvalidation_0-mlogloss:0.93843\tvalidation_0-macroF1:0.57918\n",
      "[150]\tvalidation_0-mlogloss:0.93847\tvalidation_0-macroF1:0.58042\n",
      "[200]\tvalidation_0-mlogloss:0.93756\tvalidation_0-macroF1:0.57726\n",
      "[250]\tvalidation_0-mlogloss:0.93589\tvalidation_0-macroF1:0.58541\n",
      "[299]\tvalidation_0-mlogloss:0.93606\tvalidation_0-macroF1:0.58968\n",
      "Train F1: 0.9128351179853464\n",
      "Test F1: 0.4326931582349539\n",
      "[16:18:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30547\tvalidation_0-macroF1:0.62321\n",
      "[50]\tvalidation_0-mlogloss:0.92165\tvalidation_0-macroF1:0.56081\n",
      "[100]\tvalidation_0-mlogloss:0.91869\tvalidation_0-macroF1:0.55783\n",
      "[150]\tvalidation_0-mlogloss:0.91620\tvalidation_0-macroF1:0.54999\n",
      "[200]\tvalidation_0-mlogloss:0.91636\tvalidation_0-macroF1:0.55482\n",
      "[250]\tvalidation_0-mlogloss:0.91588\tvalidation_0-macroF1:0.55061\n",
      "[299]\tvalidation_0-mlogloss:0.91556\tvalidation_0-macroF1:0.54736\n",
      "Train F1: 0.9273238446441445\n",
      "Test F1: 0.45331548653917075\n",
      "[16:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:18:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30109\tvalidation_0-macroF1:0.63195\n",
      "[50]\tvalidation_0-mlogloss:0.92433\tvalidation_0-macroF1:0.60566\n",
      "[100]\tvalidation_0-mlogloss:0.92053\tvalidation_0-macroF1:0.59748\n",
      "[150]\tvalidation_0-mlogloss:0.91912\tvalidation_0-macroF1:0.60108\n",
      "[200]\tvalidation_0-mlogloss:0.91950\tvalidation_0-macroF1:0.61223\n",
      "[250]\tvalidation_0-mlogloss:0.91865\tvalidation_0-macroF1:0.61383\n",
      "[299]\tvalidation_0-mlogloss:0.91853\tvalidation_0-macroF1:0.60909\n",
      "Train F1: 0.8604328364026029\n",
      "Test F1: 0.4192263582825215\n",
      "[16:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30172\tvalidation_0-macroF1:0.61078\n",
      "[50]\tvalidation_0-mlogloss:0.90473\tvalidation_0-macroF1:0.58278\n",
      "[100]\tvalidation_0-mlogloss:0.90000\tvalidation_0-macroF1:0.57990\n",
      "[150]\tvalidation_0-mlogloss:0.89396\tvalidation_0-macroF1:0.58043\n",
      "[200]\tvalidation_0-mlogloss:0.89226\tvalidation_0-macroF1:0.57862\n",
      "[250]\tvalidation_0-mlogloss:0.89228\tvalidation_0-macroF1:0.58604\n",
      "[299]\tvalidation_0-mlogloss:0.89270\tvalidation_0-macroF1:0.58820\n",
      "Train F1: 0.927086687566341\n",
      "Test F1: 0.42500017325799716\n",
      "[16:19:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:19:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30351\tvalidation_0-macroF1:0.64047\n",
      "[50]\tvalidation_0-mlogloss:0.90510\tvalidation_0-macroF1:0.58320\n",
      "[100]\tvalidation_0-mlogloss:0.90194\tvalidation_0-macroF1:0.58600\n",
      "[150]\tvalidation_0-mlogloss:0.90231\tvalidation_0-macroF1:0.58331\n",
      "[200]\tvalidation_0-mlogloss:0.90319\tvalidation_0-macroF1:0.57922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalidation_0-mlogloss:0.90326\tvalidation_0-macroF1:0.58032\n",
      "[299]\tvalidation_0-mlogloss:0.90476\tvalidation_0-macroF1:0.57784\n",
      "Train F1: 0.9131085061977701\n",
      "Test F1: 0.42540312297831107\n",
      "[16:20:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30457\tvalidation_0-macroF1:0.66229\n",
      "[50]\tvalidation_0-mlogloss:0.92731\tvalidation_0-macroF1:0.62286\n",
      "[100]\tvalidation_0-mlogloss:0.92147\tvalidation_0-macroF1:0.62384\n",
      "[150]\tvalidation_0-mlogloss:0.92070\tvalidation_0-macroF1:0.63108\n",
      "[200]\tvalidation_0-mlogloss:0.91867\tvalidation_0-macroF1:0.63529\n",
      "[250]\tvalidation_0-mlogloss:0.91730\tvalidation_0-macroF1:0.62598\n",
      "[299]\tvalidation_0-mlogloss:0.91654\tvalidation_0-macroF1:0.63122\n",
      "Train F1: 0.9039317978478034\n",
      "Test F1: 0.3870640568511129\n",
      "[16:20:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29708\tvalidation_0-macroF1:0.62412\n",
      "[50]\tvalidation_0-mlogloss:0.88409\tvalidation_0-macroF1:0.56213\n",
      "[100]\tvalidation_0-mlogloss:0.88135\tvalidation_0-macroF1:0.55805\n",
      "[150]\tvalidation_0-mlogloss:0.88174\tvalidation_0-macroF1:0.55302\n",
      "[200]\tvalidation_0-mlogloss:0.87978\tvalidation_0-macroF1:0.54801\n",
      "[250]\tvalidation_0-mlogloss:0.87887\tvalidation_0-macroF1:0.54403\n",
      "[299]\tvalidation_0-mlogloss:0.87894\tvalidation_0-macroF1:0.54671\n",
      "Train F1: 0.926590037660807\n",
      "Test F1: 0.45596696580867907\n",
      "[16:20:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:20:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30941\tvalidation_0-macroF1:0.67391\n",
      "[50]\tvalidation_0-mlogloss:0.90405\tvalidation_0-macroF1:0.60191\n",
      "[100]\tvalidation_0-mlogloss:0.89729\tvalidation_0-macroF1:0.59552\n",
      "[150]\tvalidation_0-mlogloss:0.89797\tvalidation_0-macroF1:0.58308\n",
      "[200]\tvalidation_0-mlogloss:0.89707\tvalidation_0-macroF1:0.60787\n",
      "[250]\tvalidation_0-mlogloss:0.89636\tvalidation_0-macroF1:0.60327\n",
      "[299]\tvalidation_0-mlogloss:0.89568\tvalidation_0-macroF1:0.59413\n",
      "Train F1: 0.9177266968021762\n",
      "Test F1: 0.4169205363356127\n",
      "[16:21:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:21:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29873\tvalidation_0-macroF1:0.64866\n",
      "[50]\tvalidation_0-mlogloss:0.93059\tvalidation_0-macroF1:0.57796\n",
      "[100]\tvalidation_0-mlogloss:0.93042\tvalidation_0-macroF1:0.58456\n",
      "[150]\tvalidation_0-mlogloss:0.93141\tvalidation_0-macroF1:0.58464\n",
      "[200]\tvalidation_0-mlogloss:0.93280\tvalidation_0-macroF1:0.58348\n",
      "[250]\tvalidation_0-mlogloss:0.93234\tvalidation_0-macroF1:0.58326\n",
      "[299]\tvalidation_0-mlogloss:0.93234\tvalidation_0-macroF1:0.58357\n",
      "Train F1: 0.8890905288434153\n",
      "Test F1: 0.4291004079449764\n",
      "[16:21:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:21:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29814\tvalidation_0-macroF1:0.63167\n",
      "[50]\tvalidation_0-mlogloss:0.93109\tvalidation_0-macroF1:0.60363\n",
      "[100]\tvalidation_0-mlogloss:0.92695\tvalidation_0-macroF1:0.60890\n",
      "[150]\tvalidation_0-mlogloss:0.92862\tvalidation_0-macroF1:0.61470\n",
      "[200]\tvalidation_0-mlogloss:0.92751\tvalidation_0-macroF1:0.60809\n",
      "[250]\tvalidation_0-mlogloss:0.92977\tvalidation_0-macroF1:0.60797\n",
      "[299]\tvalidation_0-mlogloss:0.93202\tvalidation_0-macroF1:0.61026\n",
      "Train F1: 0.9022537754659561\n",
      "Test F1: 0.42152794153781975\n",
      "[16:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29890\tvalidation_0-macroF1:0.59884\n",
      "[50]\tvalidation_0-mlogloss:0.89680\tvalidation_0-macroF1:0.57203\n",
      "[100]\tvalidation_0-mlogloss:0.89428\tvalidation_0-macroF1:0.58095\n",
      "[150]\tvalidation_0-mlogloss:0.89336\tvalidation_0-macroF1:0.57380\n",
      "[200]\tvalidation_0-mlogloss:0.89353\tvalidation_0-macroF1:0.57258\n",
      "[250]\tvalidation_0-mlogloss:0.89322\tvalidation_0-macroF1:0.57108\n",
      "[299]\tvalidation_0-mlogloss:0.89235\tvalidation_0-macroF1:0.57199\n",
      "Train F1: 0.8938569029876557\n",
      "Test F1: 0.43980449162180346\n",
      "[16:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:22:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30963\tvalidation_0-macroF1:0.63537\n",
      "[50]\tvalidation_0-mlogloss:0.92115\tvalidation_0-macroF1:0.58287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-mlogloss:0.91136\tvalidation_0-macroF1:0.58107\n",
      "[150]\tvalidation_0-mlogloss:0.90792\tvalidation_0-macroF1:0.56804\n",
      "[200]\tvalidation_0-mlogloss:0.90564\tvalidation_0-macroF1:0.56718\n",
      "[250]\tvalidation_0-mlogloss:0.90621\tvalidation_0-macroF1:0.56815\n",
      "[299]\tvalidation_0-mlogloss:0.90505\tvalidation_0-macroF1:0.57516\n",
      "Train F1: 0.9216674147144617\n",
      "Test F1: 0.43368257176436975\n",
      "[16:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[16:22:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29451\tvalidation_0-macroF1:0.62019\n",
      "[50]\tvalidation_0-mlogloss:0.87714\tvalidation_0-macroF1:0.57123\n",
      "[100]\tvalidation_0-mlogloss:0.87027\tvalidation_0-macroF1:0.57247\n",
      "[150]\tvalidation_0-mlogloss:0.86424\tvalidation_0-macroF1:0.56200\n",
      "[200]\tvalidation_0-mlogloss:0.86369\tvalidation_0-macroF1:0.55931\n",
      "[250]\tvalidation_0-mlogloss:0.86174\tvalidation_0-macroF1:0.56405\n",
      "[299]\tvalidation_0-mlogloss:0.86261\tvalidation_0-macroF1:0.56751\n",
      "Train F1: 0.9216788990707238\n",
      "Test F1: 0.4421686411590497\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n",
    "    \n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "    \n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del(clfs)\n",
    "\n",
    "#Train the final model with learning rate decay\n",
    "_ = vc.fit(X_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "\n",
    "clf_final = vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:23:39.194867Z",
     "start_time": "2021-04-16T07:23:39.013613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a single LGBM Classifier: 0.8220\n",
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8876\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "# params 4 - 400 early stop - 15 estimators - l1 used features - weighted\n",
    "global_score = f1_score(y_test, clf_final.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'hard'\n",
    "global_score_hard = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:24:16.751388Z",
     "start_time": "2021-04-16T07:24:15.241803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg18_estadocivil4_COUNT',\n",
       " 'agg18_estadocivil5_COUNT',\n",
       " 'geo_energcocinar_LE_0',\n",
       " 'geo_epared_LE_2'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see which features are not used by ANY models\n",
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(xgb_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "    \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:24:20.474507Z",
     "start_time": "2021-04-16T07:24:20.334141Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 114 (0.030279) - geo_epared_LE_1\n",
      "2. feature 42 (0.019682) - fe_children_fraction\n",
      "3. feature 74 (0.018983) - agg18_parentesco2_MEAN\n",
      "4. feature 59 (0.017248) - agg18_escolari_MAX\n",
      "5. feature 133 (0.016442) - geo_pared_LE_1\n",
      "6. feature 60 (0.014158) - agg18_escolari_MEAN\n",
      "7. feature 40 (0.013327) - SQBdependency\n",
      "8. feature 22 (0.012823) - dependency\n",
      "9. feature 34 (0.012632) - SQBescolari\n",
      "10. feature 12 (0.011761) - r4t1\n",
      "11. feature 37 (0.011632) - SQBedjefe\n",
      "12. feature 112 (0.011575) - geo_etecho_LE_1\n",
      "13. feature 126 (0.010669) - geo_sanitario_LE_3\n",
      "14. feature 96 (0.010495) - estadocivil_LE\n",
      "15. feature 116 (0.010293) - geo_elimbasu_LE_0\n",
      "16. feature 11 (0.010211) - r4m3\n",
      "17. feature 100 (0.010105) - geo_age\n",
      "18. feature 94 (0.010058) - etecho_LE\n",
      "19. feature 17 (0.009895) - male\n",
      "20. feature 105 (0.009877) - geo_hogar_total\n",
      "21. feature 87 (0.009871) - piso_LE\n",
      "22. feature 39 (0.009789) - SQBovercrowding\n",
      "23. feature 63 (0.009531) - agg18_estadocivil2_MEAN\n",
      "24. feature 117 (0.009491) - geo_elimbasu_LE_1\n",
      "25. feature 41 (0.009429) - SQBmeaned\n",
      "26. feature 95 (0.009387) - eviv_LE\n",
      "27. feature 49 (0.009266) - fe_mobile_density\n",
      "28. feature 104 (0.009116) - geo_hogar_adul\n",
      "29. feature 15 (0.009112) - cielorazo\n",
      "30. feature 23 (0.008963) - edjefe\n",
      "31. feature 93 (0.008881) - epared_LE\n",
      "32. feature 65 (0.008877) - agg18_estadocivil3_MEAN\n",
      "33. feature 124 (0.008846) - geo_sanitario_LE_1\n",
      "34. feature 109 (0.008796) - geo_eviv_LE_1\n",
      "35. feature 98 (0.008791) - tipovivi_LE\n",
      "36. feature 107 (0.008772) - geo_overcrowding\n",
      "37. feature 19 (0.008759) - hogar_adul\n",
      "38. feature 13 (0.008726) - r4t2\n",
      "39. feature 106 (0.008656) - geo_bedrooms\n",
      "40. feature 51 (0.008552) - fe_mobile_adult_density\n",
      "41. feature 27 (0.008478) - overcrowding\n",
      "42. feature 55 (0.008476) - agg18_age_MIN\n",
      "43. feature 31 (0.008450) - area1\n",
      "44. feature 58 (0.008433) - agg18_escolari_MIN\n",
      "45. feature 119 (0.008352) - geo_elimbasu_LE_3\n",
      "46. feature 14 (0.008237) - escolari\n",
      "47. feature 25 (0.008114) - meaneduc\n",
      "48. feature 86 (0.008095) - pared_LE\n",
      "49. feature 33 (0.008083) - age\n",
      "50. feature 7 (0.008060) - r4h2\n",
      "51. feature 120 (0.007983) - geo_elimbasu_LE_5\n",
      "52. feature 69 (0.007941) - agg18_estadocivil5_MEAN\n",
      "53. feature 97 (0.007922) - lugar_LE\n",
      "54. feature 123 (0.007897) - geo_sanitario_LE_0\n",
      "55. feature 35 (0.007885) - SQBage\n",
      "56. feature 71 (0.007873) - agg18_estadocivil6_MEAN\n",
      "57. feature 44 (0.007848) - fe_all_man_fraction\n",
      "58. feature 102 (0.007817) - geo_dependency\n",
      "59. feature 92 (0.007798) - elimbasu_LE\n",
      "60. feature 62 (0.007746) - agg18_estadocivil1_COUNT\n",
      "61. feature 45 (0.007711) - fe_human_density\n",
      "62. feature 0 (0.007631) - v2a1\n",
      "63. feature 56 (0.007629) - agg18_age_MAX\n",
      "64. feature 122 (0.007584) - geo_energcocinar_LE_3\n",
      "65. feature 8 (0.007526) - r4h3\n",
      "66. feature 136 (0.007525) - bedrooms_to_rooms\n",
      "67. feature 91 (0.007479) - energcocinar_LE\n",
      "68. feature 10 (0.007478) - r4m2\n",
      "69. feature 43 (0.007475) - fe_working_man_fraction\n",
      "70. feature 5 (0.007457) - v18q1\n",
      "71. feature 47 (0.007435) - fe_rent_per_person\n",
      "72. feature 4 (0.007360) - refrig\n",
      "73. feature 137 (0.007317) - rent_to_rooms\n",
      "74. feature 26 (0.007297) - bedrooms\n",
      "75. feature 128 (0.007238) - geo_manual_elec_LE_0\n",
      "76. feature 61 (0.007208) - agg18_dis_MEAN\n",
      "77. feature 24 (0.007182) - edjefa\n",
      "78. feature 30 (0.007106) - qmobilephone\n",
      "79. feature 85 (0.007052) - edjef\n",
      "80. feature 72 (0.006995) - agg18_estadocivil7_MEAN\n",
      "81. feature 36 (0.006962) - SQBhogar_total\n",
      "82. feature 90 (0.006927) - sanitario_LE\n",
      "83. feature 29 (0.006899) - television\n",
      "84. feature 21 (0.006897) - hogar_total\n",
      "85. feature 2 (0.006891) - rooms\n",
      "86. feature 125 (0.006886) - geo_sanitario_LE_2\n",
      "87. feature 16 (0.006851) - dis\n",
      "88. feature 18 (0.006810) - hogar_nin\n",
      "89. feature 143 (0.006710) - rent_to_hhsize\n",
      "90. feature 57 (0.006687) - agg18_age_MEAN\n",
      "91. feature 138 (0.006636) - tamhog_to_rooms\n",
      "92. feature 64 (0.006620) - agg18_estadocivil2_COUNT\n",
      "93. feature 52 (0.006611) - fe_tablet_adult_density\n",
      "94. feature 48 (0.006435) - fe_rent_per_room\n",
      "95. feature 6 (0.006235) - r4h1\n",
      "96. feature 1 (0.005999) - hacdor\n",
      "97. feature 99 (0.005923) - manual_elec_LE\n",
      "98. feature 129 (0.005903) - geo_manual_elec_LE_1\n",
      "99. feature 50 (0.005864) - fe_tablet_density\n",
      "100. feature 144 (0.005774) - rent_to_over_18\n",
      "101. feature 79 (0.005734) - agg18_parentesco7_MEAN\n",
      "102. feature 20 (0.005656) - hogar_mayor\n",
      "103. feature 89 (0.005596) - abastagua_LE\n",
      "104. feature 38 (0.005586) - SQBhogar_nin\n",
      "105. feature 111 (0.005451) - geo_etecho_LE_0\n",
      "106. feature 67 (0.005196) - agg18_estadocivil4_MEAN\n",
      "107. feature 88 (0.005127) - techo_LE\n",
      "108. feature 3 (0.005073) - hacapo\n",
      "109. feature 75 (0.004926) - agg18_parentesco3_MEAN\n",
      "110. feature 28 (0.004834) - computer\n",
      "111. feature 81 (0.004800) - agg18_parentesco9_MEAN\n",
      "112. feature 141 (0.004748) - v2a1_to_r4t3\n",
      "113. feature 9 (0.004701) - r4m1\n",
      "114. feature 140 (0.004519) - r4t3_to_rooms\n",
      "115. feature 77 (0.004361) - agg18_parentesco5_MEAN\n",
      "116. feature 53 (0.004182) - fe_people_not_living\n",
      "117. feature 32 (0.004033) - area2\n",
      "118. feature 78 (0.003952) - agg18_parentesco6_MEAN\n",
      "119. feature 83 (0.003865) - agg18_parentesco11_MEAN\n",
      "120. feature 101 (0.003449) - geo_meaneduc\n",
      "121. feature 76 (0.002761) - agg18_parentesco4_MEAN\n",
      "122. feature 142 (0.002618) - hhsize_to_rooms\n",
      "123. feature 84 (0.002575) - agg18_parentesco12_MEAN\n",
      "124. feature 139 (0.001424) - r4t3_to_tamhog\n",
      "125. feature 80 (0.001382) - agg18_parentesco8_MEAN\n",
      "126. feature 113 (0.000000) - geo_etecho_LE_2\n",
      "127. feature 134 (0.000000) - geo_pared_LE_2\n",
      "128. feature 68 (0.000000) - agg18_estadocivil4_COUNT\n",
      "129. feature 70 (0.000000) - agg18_estadocivil5_COUNT\n",
      "130. feature 46 (0.000000) - fe_human_bed_density\n",
      "131. feature 73 (0.000000) - agg18_parentesco1_MEAN\n",
      "132. feature 135 (0.000000) - geo_pared_LE_7\n",
      "133. feature 132 (0.000000) - geo_pared_LE_0\n",
      "134. feature 115 (0.000000) - geo_epared_LE_2\n",
      "135. feature 110 (0.000000) - geo_eviv_LE_2\n",
      "136. feature 130 (0.000000) - geo_manual_elec_LE_3\n",
      "137. feature 103 (0.000000) - geo_hogar_nin\n",
      "138. feature 54 (0.000000) - fe_people_weird_stat\n",
      "139. feature 127 (0.000000) - geo_sanitario_LE_4\n",
      "140. feature 66 (0.000000) - agg18_estadocivil3_COUNT\n",
      "141. feature 108 (0.000000) - geo_eviv_LE_0\n",
      "142. feature 82 (0.000000) - agg18_parentesco10_MEAN\n",
      "143. feature 121 (0.000000) - geo_energcocinar_LE_0\n",
      "144. feature 118 (0.000000) - geo_elimbasu_LE_2\n",
      "145. feature 131 (0.000000) - geo_manual_elec_LE_4\n"
     ]
    }
   ],
   "source": [
    "ranked_features = feature_importance(clf_final, X_train.drop(xgb_drop_cols, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:24:28.620078Z",
     "start_time": "2021-04-16T07:24:28.609978Z"
    }
   },
   "outputs": [],
   "source": [
    "et_drop_cols = ['agg18_age_MAX', 'agg18_age_MEAN', 'agg18_age_MIN', 'agg18_dis_MEAN',\n",
    "       'agg18_escolari_MAX', 'agg18_escolari_MEAN', 'agg18_escolari_MIN',\n",
    "       'agg18_estadocivil1_COUNT', 'agg18_estadocivil1_MEAN',\n",
    "       'agg18_estadocivil2_COUNT', 'agg18_estadocivil2_MEAN',\n",
    "       'agg18_estadocivil3_COUNT', 'agg18_estadocivil3_MEAN',\n",
    "       'agg18_estadocivil4_COUNT', 'agg18_estadocivil4_MEAN',\n",
    "       'agg18_estadocivil5_COUNT', 'agg18_estadocivil5_MEAN',\n",
    "       'agg18_estadocivil6_COUNT', 'agg18_estadocivil6_MEAN',\n",
    "       'agg18_estadocivil7_COUNT', 'agg18_estadocivil7_MEAN',\n",
    "       'agg18_parentesco10_COUNT', 'agg18_parentesco10_MEAN',\n",
    "       'agg18_parentesco11_COUNT', 'agg18_parentesco11_MEAN',\n",
    "       'agg18_parentesco12_COUNT', 'agg18_parentesco12_MEAN',\n",
    "       'agg18_parentesco1_COUNT', 'agg18_parentesco1_MEAN',\n",
    "       'agg18_parentesco2_COUNT', 'agg18_parentesco2_MEAN',\n",
    "       'agg18_parentesco3_COUNT', 'agg18_parentesco3_MEAN',\n",
    "       'agg18_parentesco4_COUNT', 'agg18_parentesco4_MEAN',\n",
    "       'agg18_parentesco5_COUNT', 'agg18_parentesco5_MEAN',\n",
    "       'agg18_parentesco6_COUNT', 'agg18_parentesco6_MEAN',\n",
    "       'agg18_parentesco7_COUNT', 'agg18_parentesco7_MEAN',\n",
    "       'agg18_parentesco8_COUNT', 'agg18_parentesco8_MEAN',\n",
    "       'agg18_parentesco9_COUNT', 'agg18_parentesco9_MEAN'] #+ ['parentesco_LE', 'rez_esc']\n",
    "\n",
    "et_drop_cols.extend([\"idhogar\", \"parentesco1\", 'fe_rent_per_person', 'fe_rent_per_room',\n",
    "       'fe_tablet_adult_density', 'fe_tablet_density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:24:54.747762Z",
     "start_time": "2021-04-16T07:24:33.721786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.8995785797400715\n",
      "Test F1: 0.41644760797490754\n",
      "Train F1: 0.8974057100172891\n",
      "Test F1: 0.4173294959009245\n",
      "Train F1: 0.8929947876700697\n",
      "Test F1: 0.380791318982666\n",
      "Train F1: 0.8897229006999118\n",
      "Test F1: 0.43258661725401276\n",
      "Train F1: 0.8894013811159895\n",
      "Test F1: 0.46517518214144904\n",
      "Train F1: 0.8963246456113938\n",
      "Test F1: 0.426575122901441\n",
      "Train F1: 0.890822628612706\n",
      "Test F1: 0.41104823629263454\n",
      "Train F1: 0.8958771082511664\n",
      "Test F1: 0.46546114892390233\n",
      "Train F1: 0.9064600301011827\n",
      "Test F1: 0.4286664637370844\n",
      "Train F1: 0.8948837246950454\n",
      "Test F1: 0.41037179469569823\n"
     ]
    }
   ],
   "source": [
    "# do the same thing for some extra trees classifiers\n",
    "ets = []    \n",
    "for i in range(10):\n",
    "    rf = RandomForestClassifier(max_depth=None, random_state=217+i, n_jobs=4, n_estimators=700, min_impurity_decrease=1e-3, min_samples_leaf=2, verbose=0, class_weight=\"balanced\")\n",
    "    ets.append(('rf{}'.format(i), rf))   \n",
    "\n",
    "vc2 = VotingClassifierLGBM(ets, voting='soft')    \n",
    "_ = vc2.fit(X_train.drop(et_drop_cols, axis=1), y_train, threshold=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:12.346160Z",
     "start_time": "2021-04-16T07:25:10.626814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8379\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8499\n"
     ]
    }
   ],
   "source": [
    "# w/ threshold, extra drop cols\n",
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:16.269382Z",
     "start_time": "2021-04-16T07:25:14.373248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.8379\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.8499\n"
     ]
    }
   ],
   "source": [
    "# w/o threshold, extra drop cols\n",
    "vc2.voting = 'soft'\n",
    "global_rf_score_soft = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "vc2.voting = 'hard'\n",
    "global_rf_score_hard = f1_score(y_test, vc2.predict(X_test.drop(et_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_rf_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_rf_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:31.597109Z",
     "start_time": "2021-04-16T07:25:31.027951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parentesco_LE', 'rez_esc'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see which features are not used by ANY models\n",
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc2.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(et_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "    \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:38.555339Z",
     "start_time": "2021-04-16T07:25:38.537382Z"
    }
   },
   "outputs": [],
   "source": [
    "def combine_voters(data, weights=[0.5, 0.5]):\n",
    "    # do soft voting with both classifiers\n",
    "    vc.voting=\"soft\"\n",
    "    vc1_probs = vc.predict_proba(data.drop(xgb_drop_cols, axis=1))\n",
    "    vc2.voting=\"soft\"\n",
    "    vc2_probs = vc2.predict_proba(data.drop(et_drop_cols, axis=1))\n",
    "    \n",
    "    final_vote = (vc1_probs * weights[0]) + (vc2_probs * weights[1])\n",
    "    predictions = np.argmax(final_vote, axis=1)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:46.601054Z",
     "start_time": "2021-04-16T07:25:45.634249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8902509459276232"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.5, 0.5])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:51.142576Z",
     "start_time": "2021-04-16T07:25:50.193527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8799250865445447"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.4, 0.6])\n",
    "global_combo_score_soft= f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:25:57.757885Z",
     "start_time": "2021-04-16T07:25:56.778504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8928776032611756"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_preds = combine_voters(X_test, weights=[0.6, 0.4])\n",
    "global_combo_score_soft = f1_score(y_test, combo_preds, average='macro')\n",
    "global_combo_score_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:26:05.526639Z",
     "start_time": "2021-04-16T07:26:05.505572Z"
    }
   },
   "outputs": [],
   "source": [
    "y_subm = pd.DataFrame()\n",
    "y_subm['Id'] = test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:26:29.413231Z",
     "start_time": "2021-04-16T07:26:11.939532Z"
    }
   },
   "outputs": [],
   "source": [
    "vc.voting = 'soft'\n",
    "y_subm_lgb = y_subm.copy(deep=True)\n",
    "y_subm_lgb['Target'] = vc.predict(test.drop(xgb_drop_cols, axis=1)) + 1\n",
    "\n",
    "vc2.voting = 'soft'\n",
    "y_subm_rf = y_subm.copy(deep=True)\n",
    "y_subm_rf['Target'] = vc2.predict(test.drop(et_drop_cols, axis=1)) + 1\n",
    "\n",
    "y_subm_ens = y_subm.copy(deep=True)\n",
    "y_subm_ens['Target'] = combine_voters(test) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T07:26:52.566471Z",
     "start_time": "2021-04-16T07:26:52.458325Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "\n",
    "sub_file_lgb = 'submission_soft_XGB_{:.4f}_{}.csv'.format(global_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_rf = 'submission_soft_RF_{:.4f}_{}.csv'.format(global_rf_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "sub_file_ens = 'submission_ens_{:.4f}_{}.csv'.format(global_combo_score_soft, str(now.strftime('%Y-%m-%d-%H-%M')))\n",
    "\n",
    "y_subm_lgb.to_csv(sub_file_lgb, index=False)\n",
    "y_subm_rf.to_csv(sub_file_rf, index=False)\n",
    "y_subm_ens.to_csv(sub_file_ens, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
